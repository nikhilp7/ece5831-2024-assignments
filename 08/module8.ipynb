{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import os\n",
    "\n",
    "class LeNet:\n",
    "    def __init__(self, batch_size=32, epochs=20):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self._create_lenet()\n",
    "        self._compile()\n",
    "\n",
    "    def _create_lenet(self):\n",
    "    \n",
    "        self.model = Sequential([\n",
    "            Conv2D(filters=6, kernel_size=(5, 5), activation='sigmoid',\n",
    "                   input_shape=(28, 28, 1), padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "            \n",
    "            Conv2D(filters=16, kernel_size=(5, 5), activation='sigmoid', padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "            \n",
    "            Flatten(),\n",
    "            Dense(120, activation='sigmoid'),\n",
    "            Dense(84, activation='sigmoid'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    def _compile(self):\n",
    "        \"\"\"\n",
    "        Compile the LeNet model with an Adam optimizer and categorical crossentropy loss.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError('Error: Model is not created yet.')\n",
    "        \n",
    "        self.model.compile(optimizer='Adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    def _preprocess(self):\n",
    "        \"\"\"\n",
    "        Preprocess the MNIST dataset: normalize, reshape, and one-hot encode the labels.\n",
    "        \"\"\"\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        \n",
    "        # Normalize the pixel values to the range [0, 1]\n",
    "        x_train = x_train / 255.0\n",
    "        x_test = x_test / 255.0\n",
    "        \n",
    "        # Add channel dimension\n",
    "        self.x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "        self.x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "        \n",
    "        # One-hot encode the labels\n",
    "        self.y_train = to_categorical(y_train, 10)\n",
    "        self.y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model using the preprocessed MNIST dataset.\n",
    "        \"\"\"\n",
    "        self._preprocess()\n",
    "        self.model.fit(self.x_train, self.y_train, \n",
    "                       batch_size=self.batch_size, \n",
    "                       epochs=self.epochs,\n",
    "                       validation_data=(self.x_test, self.y_test))\n",
    "\n",
    "    def save(self, model_path_name):\n",
    "        \"\"\"\n",
    "        Save the trained model to the specified file path.\n",
    "        \"\"\"\n",
    "        if not model_path_name.endswith(\".keras\"):\n",
    "            model_path_name += \".keras\"\n",
    "        self.model.save(model_path_name)\n",
    "        print(f\"Model saved as {model_path_name}\")\n",
    "\n",
    "    def load(self, model_path_name):\n",
    "        \"\"\"\n",
    "        Load a saved model from the specified file path.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(model_path_name):\n",
    "            raise FileNotFoundError(f\"No such file: {model_path_name}\")\n",
    "        self.model = load_model(model_path_name)\n",
    "        print(f\"Model loaded from {model_path_name}\")\n",
    "\n",
    "    def predict(self, images):\n",
    "        \"\"\"\n",
    "        Predict the class probabilities for a list of images.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model is not loaded or created yet.\")\n",
    "        \n",
    "        # Preprocess images: normalize and add channel dimension\n",
    "        images = [img / 255.0 for img in images]\n",
    "        images = [img.reshape(1, 28, 28, 1) for img in images]\n",
    "        \n",
    "        # Run predictions and return results\n",
    "        predictions = [self.model.predict(img, verbose=0) for img in images]\n",
    "        return [pred.argmax() for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = LeNet(batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 5ms/step - loss: 1.0541 - accuracy: 0.6486 - val_loss: 0.3002 - val_accuracy: 0.9148\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2294 - accuracy: 0.9308 - val_loss: 0.1684 - val_accuracy: 0.9501\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1509 - accuracy: 0.9546 - val_loss: 0.1306 - val_accuracy: 0.9604\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1164 - accuracy: 0.9644 - val_loss: 0.1046 - val_accuracy: 0.9674\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0932 - accuracy: 0.9714 - val_loss: 0.0864 - val_accuracy: 0.9725\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.0670 - val_accuracy: 0.9791\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0685 - accuracy: 0.9785 - val_loss: 0.0619 - val_accuracy: 0.9799\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.0584 - val_accuracy: 0.9813\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0546 - accuracy: 0.9828 - val_loss: 0.0493 - val_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.0469 - val_accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as pawar.keras\n"
     ]
    }
   ],
   "source": [
    "lenet.save(\"pawar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from pawar.keras\n"
     ]
    }
   ],
   "source": [
    "lenet.load(\"pawar.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lenet.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "def process_images_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Load and process all images from a folder, ensuring each image is (28, 28) (grayscale).\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of processed images, each with shape (28, 28).\n",
    "    \"\"\"\n",
    "    processed_images = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Ensure it's a valid image file\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image = cv2.imread(file_path)  # Load image\n",
    "            \n",
    "            if image is not None:  # Check if image is loaded successfully\n",
    "                # Convert to grayscale (if it's not already)\n",
    "                grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Resize to 28x28\n",
    "                resized_image = cv2.resize(grayscale_image, (28, 28))\n",
    "                \n",
    "                # Append to the list\n",
    "                processed_images.append(resized_image)\n",
    "    \n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8, 3, 3, 8, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"H:/MS 2.0/UMDearborn/Courses/Pattern Recognition and neural network/Assignments/Nikhil_Assignments/test_images/\" \n",
    "test_images = process_images_from_folder(folder_path)\n",
    "\n",
    "# Predict with LeNet\n",
    "predictions = lenet.predict(test_images)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UMICH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
